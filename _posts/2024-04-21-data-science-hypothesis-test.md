---
title: Data-Science - 가설검정(Hypothesis Test)

date: 2024-06-08 21:44 +/-09:00
category: [data science]
tag: [data science, test]
---

- [**유의성 검정**](#유의성-검정)
  - [**A/B 검정**](#ab-검정)
  - [**가설검정**](#가설-검정)
  - [**재표본추출**](#재표본추출)
    - [**부트스트랩**](#부트스트랩)
    - [**순열검정**](#순열검정)
  - [**카이제곱검정**](#카이제곱검정)
    - [**자유도**](#자유도)
  - [**p값**](#p값)
    - [**p값 논란**](#p값-논란)
  - [**t검정**](#t검정)
  - [**f검정**](#f검정)
  - [**분산분석**](#분산분석)
  - [**다중검정**](#다중검정)

---

# **유의성 검정**

유의성 검정을 하는 이유는 다양한데, 연구 또는 실험에서 세운 가설이 통계적으로 유의미한지 확인하기 위해서, 결과의 신뢰성을 높이기 위해서, 오류를 줄이기 위해서 등의 이유로 사용된다.

## **A/B 검정**

두 가지 처리 방법 중 어느 쪽이 다른 쪽보다 비교우위에 있는지 입증하기 위해 진행한다.

다음과 같은 용어들이 등장한다.

**처리(treatment)**: 대상에 주어지는 환경이나 조건  
**처리군(treatment group)**: 처리 대상 집단  
**대조군(control group)**: 아무 처리도 하지 않은 대상 집단  
**임의화(randomization)**: 처리 대상을 임의로 결정하는 과정  
**대상(subject)**: 처리 적용의 대상  
**검정통계량(test statistics)**: 처리 효과의 측정 지표  

| 과일  | 사과   | 배    |
|-------|--------|-------|
| 판매  | 136    | 54    |
| 가격  | 1600   | 4500  |

예컨대 이렇게 많은 과일들을 판매할 경우 가격의 비교를 해야 어떤 품목이 더 많은 마진을 올렸는지 알 수 있다.

| 과일  | 사과   | 배    |
|-------|--------|-------|
| 판매 수익 | 217,600 | 243,000 |

사과의 판매가 더 많았으나 배의 판매 수익이 더 높은 걸로 확인되었다. 여기서 판매는 횟수형 변수이며, 수익은 연속형 변수다. A/B 검정은 주로 마케팅 분야에서 널리 사용된다.

## **가설 검정**

**가설검정(hypothesis test)** 또는 **유의성검정(significance test)** 이라고도 한다. 관찰된 효과가 우연인지에 대해 알아내는 것이 목표다.

용어는 다음과 같다.

**귀무가설(null hypothesis)**: 우연 때문이라는 가설  
**대립가설(alternative hypothesis)**: 귀무가설의 대조다. 쉽게 말해 내가 증명하고자 하는 가설이다.  
**일원검정(one-way test)**: 단방향에서 우연히 일어날 확률을 계산하는 가설검정 (A -> B)  
**이원검정(two-way test)**: 양방향에서 우연히 일어날 확률을 계산하는 가설검정 (A <--> B)  

* 귀무가설은 해당 사건이 우연히 발생했다는 이야기다. 로또 당첨은 운이라는 것이 예시다.
* 대립가설은 귀무가설에 더해 대립하는 가설을 포함한다. 로또에 당첨되려 여러 차례 구매했다는 증거가 대표적인 예다.
* 일원검정은 하나의 독립변수(요인)가 종속변수에 미치는 영향을 분석하는 통계적 방법이다. 즉, 하나의 요인만을 고려하여 그 요인이 종속변수에 어떤 차이를 발생시키는지를 검정한다. 예를 들어, 다양한 교육 방법(전통적 교육 vs. 온라인 교육)이 학생들의 시험 성적에 미치는 영향을 분석할 때 일원검정을 사용할 수 있다.
* 이원검정은 두 개의 독립변수가 종속변수에 미치는 영향을 분석하는 방법이다. 각 요인의 독립적인 효과뿐만 아니라, 두 요인의 상호작용 효과도 검정할 수 있다. 예를 들어, 교육 방법(전통적 교육 vs. 온라인 교육)과 학생의 성별(남학생 vs. 여학생)이 시험 성적에 미치는 영향을 동시에 분석할 때 이원검정을 사용할 수 있다.

## **재표본추출**

**재표본추출**은 통계적 추론을 강화하기 위해 원본 데이터를 반복적으로 샘플링하여 분석하는 기법이다. 주요 방법으로 **부트스트랩** 과 **순열검정** 이 있다.

### 부트스트랩
- 부트스트랩(bootstrap)은 주어진 표본 데이터에서 반복적으로 무작위로 표본을 추출하여 여러 개의 "재표본"을 생성하는 방법이다. 이를 통해 표본 통계량의 분포를 추정하고, 신뢰 구간이나 표준 오차 등을 계산할 수 있다.
- 데이터의 분포를 잘 모를 때, 표본 크기가 작을 때 유용하다. 예를 들어, 평균, 분산 등의 통계량에 대한 신뢰 구간을 구할 때 사용된다.

### 순열검정
- 순열검정은 두 개 이상의 집단 간의 차이를 평가할 때, 데이터의 레이블을 무작위로 재배치하여 각 재배치에 대해 통계량을 계산하는 방법이다. 귀무가설 하에서 관측된 통계량이 얼마나 극단적인지를 평가한다.
- 두 집단 간의 차이가 우연에 의한 것인지 아니면 실제로 유의미한 차이가 있는지를 검증할 때 사용된다. 예를 들어, 두 그룹의 평균이 동일한지 검정할 때 사용된다.

## **카이제곱검정**

**카이제곱검정(Chi-Square Test)** 은 명목형 데이터에서 관찰된 빈도와 기대되는 빈도 간의 차이를 검정하는 통계적 방법이다.

- **독립성 검정**
두 범주형 변수 간에 독립적인지 아니면 상관관계가 있는지를 검정하는 방법이다.
예를 들어, 성별과 흡연 여부가 독립적인지 여부를 검정할 때 사용된다.

- **적합도 검정**
한 범주형 변수의 관찰 빈도가 예상 분포와 일치하는지를 검정하는 방법이다.
예를 들어, 주사위가 공정한지 여부를 검정할 때 사용된다.

카이제곱검정은 주로 범주형 데이터 분석에 유용하며, 표본의 크기가 충분히 클 때 사용되는 것이 좋다.

다음과 같은 용어가 있다.

**카이제곱통계량(chi-square statistic)**: 기댓값으로부터 관찰값까지의 거리 측정치  
**기댓값(expectation, expected)**: 가정(보통 귀무가설)으로부터 데이터 발생 시의 기댓값  

### **자유도**

**자유도(Degrees of Freedom)** 는 통계 검정에서 사용되는 중요한 개념으로, 독립적으로 변할 수 있는 변수의 수를 의미한다. 자유도는 일반적으로 표본 크기와 관련이 있으며, 통계량의 분포를 결정하는 데 중요한 역할을 한다.

- 카이제곱검정에서 자유도는 관찰된 빈도와 기대된 빈도 간의 차이를 계산할 때 사용되는 독립적인 데이터 포인트의 수를 나타낸다.
- 계산 방법:
  - **적합도 검정**: 자유도는 카테고리의 수에서 1을 뺀 값이다. 예를 들어, 6개의 카테고리를 가진 데이터의 경우, 자유도는 6 - 1 = 5이다.
  - **독립성 검정**: 자유도는 (행의 수 - 1) * (열의 수 - 1)로 계산된다. 예를 들어, 3x4 표의 경우, 자유도는 (3 - 1) * (4 - 1) = 2 * 3 = 6이다.

자유도는 통계 검정에서 중요한 역할을 하며, 검정 통계량의 분포를 결정하는 데 사용된다. 이를 통해 귀무가설을 기각할지 여부를 판단할 수 있다.

## **p값**

**p값(p-value)** 은 통계적 가설 검정에서 귀무가설이 참이라는 가정 하에, 관찰된 결과가 나타날 확률을 나타내는 값이다. p값이 작을수록 관찰된 결과가 우연히 발생할 확률이 낮음을 의미하며, 통상적으로 p값이 0.05보다 작으면 귀무가설을 기각하고 대립가설을 채택한다.

### **p값 논란**

ASA의 2016년 p값에 대한 성명은 다음과 같은 6가지 주요 원칙을 포함하고 있다:

* p값은 데이터가 귀무가설 하에서 관찰될 확률을 나타낸다.
* p값은 데이터가 귀무가설 하에서 관찰되거나 더 극단적인 결과가 나타날 확률을 나타낸다. p값이 낮을수록 관찰된 결과가 우연히 발생할 가능성이 낮다는 것을 의미한다.
* p값은 연구 가설의 진위를 평가할 수 없다. p값은 연구 가설이 참인지 거짓인지에 대한 직접적인 증거를 제공하지 않는다. p값은 단지 귀무가설 하에서 데이터가 나타날 확률을 제공할 뿐이다.
* p값만으로 효과의 크기나 중요성을 측정할 수 없다. p값은 효과의 크기나 실제 중요성을 반영하지 않는다. 연구자들은 효과 크기, 신뢰 구간 등 다른 통계적 방법을 함께 사용하여 결과를 해석해야 한다.
* 의사결정의 유일한 기준으로 p값을 사용해서는 안 된다. p값은 의사결정을 내리는 유일한 기준으로 사용되어서는 안 된다. 연구자들은 과학적 맥락, 연구 설계, 데이터 품질 등을 종합적으로 고려해야 한다.
* 재현성과 투명성을 높이기 위해 데이터 분석 방법을 명확히 기술해야 한다. 연구자들은 데이터 분석 방법과 절차를 명확히 기술하여 다른 연구자들이 결과를 재현할 수 있도록 해야 한다. 이는 연구 결과의 신뢰성을 높이는 데 필수적이다.
* p값 이외의 통계적 방법도 함께 사용해야 한다. 연구자들은 p값뿐만 아니라 효과 크기, 신뢰 구간, 베이지안 방법 등 다양한 통계적 방법을 사용하여 보다 종합적인 결과 해석을 해야 한다. 이를 통해 연구의 신뢰성과 타당성을 높일 수 있다.

이 6가지 원칙은 p값의 올바른 사용과 해석을 촉진하고, 통계적 분석의 신뢰성을 높이는 데 목적이 있다.

## **t검정**
두 집단 간의 평균 차이가 유의미한지를 검증할 때 사용된다.

**t검정(t-test)** 은 두 집단 간의 평균 차이를 비교하는 통계적 방법이다. 이는 두 집단이 동일한 모집단에서 추출되었는지를 검정하는 데 사용된다.

* 독립표본 t검정 (Independent t-test)
두 독립된 집단 간의 평균 차이를 비교한다. 예를 들어, 남학생과 여학생의 시험 성적을 비교할 때 사용된다.

* 대응표본 t검정 (Paired t-test)
동일한 집단에서 두 번 측정한 값의 평균 차이를 비교한다. 예를 들어, 같은 학생들의 교육 전후 시험 성적을 비교할 때 사용된다.


## **f검정**

**f검정(F-test)** 은 두 개 이상의 집단 간의 분산을 비교하는 통계적 방법이다.
집단 간의 분산비율을 비교하여 두 집단이 동일한 분산을 가지는지를 검정한다. f값이 클수록 집단 간의 차이가 크다는 것을 의미한다. 주로 ANOVA에서 사용된다.

**분산분석(ANOVA)**: 여러 집단 간의 평균 차이를 비교하는 데 사용되며, 각 집단의 분산을 비교하여 유의미한 차이가 있는지를 평가한다.
**회귀분석**: 회귀 모델의 적합성을 평가할 때 사용된다.

## **분산분석**
**분산분석(Analysis of Variance, ANOVA)** 은 세 개 이상의 집단 간의 평균을 비교하는 통계적 방법이다. ANOVA는 집단 간의 차이가 우연에 의한 것인지, 아니면 실제로 유의미한 차이가 있는지를 판단하는 데 사용된다.

* 일원분산분석 (One-Way ANOVA)
  - 하나의 독립변수(요인)와 종속변수 간의 관계를 분석하는 방법이다. 예를 들어, 세 가지 다른 교육 방법이 학생들의 시험 성적에 미치는 영향을 비교할 때 사용된다.
  - 집단 간의 평균 차이를 비교하여 특정 처리가 효과가 있는지를 검증할 때 사용된다.

* 이원분산분석 (Two-Way ANOVA)
  - 두 개의 독립변수가 종속변수에 미치는 영향을 동시에 분석하는 방법이다. 각 요인의 독립적인 효과뿐만 아니라, 두 요인의 상호작용 효과도 분석할 수 있다. 예를 들어, 교육 방법과 성별이 학생들의 시험 성적에 미치는 영향을 동시에 분석할 때 사용된다.
  - 두 가지 요인이 동시에 영향을 미치는 경우, 각 요인의 주효과와 상호작용 효과를 검증할 때 사용된다.

## **다중검정**

**다중검정(Multiple Testing)** 은 여러 개의 통계적 가설을 동시에 검정할 때 발생하는 문제를 다룬다. 다중검정에서는 개별 검정의 유의수준을 유지하면서 전체 오류율을 조절하는 것이 중요하다.

용어는 다음과 같다.

**제1종 오류(Type I error)**: 실제로는 참인 귀무가설을 기각하는 오류  
**거짓발견비율(False Discovery Rate, FDR)**: 거짓으로 발견된 가설 기각의 비율  
**알파 인플레이션(Alpha Inflation)**: 다중검정 시 유의수준이 증가하는 현상  
**p값 조정(p-value adjustment)**: 다중검정에서 유의수준을 조절하기 위해 p값을 조정하는 방법  
**오버피팅(Overfitting)**: 모델이 학습 데이터에 과도하게 적합하여 새로운 데이터에 대해 일반화 성능이 떨어지는 현상  

다중검정 문제를 해결하기 위해 여러 방법이 사용된다. 대표적인 방법으로는 본페로니 보정(Bonferroni correction), 홀름 보정(Holm correction), 벤자미니-호크버그 절차(Benjamini-Hochberg procedure) 등이 있다. 이 방법들은 다중검정에서 발생하는 제1종 오류를 조절하여 신뢰할 수 있는 결과를 얻는 데 도움을 준다.
